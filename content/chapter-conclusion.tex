\chapter{Conclusion} \label{chap:conclusion}
This chapter concludes this thesis. In \autoref{sec:conclusion:future-work}, we want to take the opportunity to elaborate on steps with which to carry this research further in publications or subsequent master thesises. In \autoref{sec:conclusion:verdict} we briefly recapitulate our work and draw it to a conclusion.

\section{Future Work} \label{sec:conclusion:future-work}
We cluster the future work by items which why we believe to be of importance for future research around Predictive Process Monitoring:\\

\noindent\textbf{Benchmarking dataset:} Everything in machine learning starts and ends with the available data. Based on the numerous publications on Predictive Process Monitoring we read, we believe that it is time to draw up exemplary benchmarking datasets close to real-world scenarios. Maybe these datasets can represent industry-typical processes. Otherwise the number of datasets to use to ensure comparability will only ever increase.\\

\noindent\textbf{Imbalanced classes:} While our approach at pre-processing the data covered the basics, a necessity to balance the distribution of classes in the target data remains. We do not believe it is viable to modify the traces themselves, but weighting classes based on their occurence in the current batch might be an option which could see accuracy gains as models learn better with a balanced target class distribution~\cite{web:stackoverflow-keras-class-weights}.\\

\noindent\textbf{PFS feature engineering and hyper-parameter tuning:} The PFS model features  were chosen to be the 25 closed subsequences with the highest support. This threshold should be explored further. Furthermore, none of the model's hyper-parameters were optimized for lack of a functional framework. In this area, another contribution can be made.\\

\noindent\textbf{Concept drift:} Processes change over time and so does the content of their event logs. It is worth investigating at which point data can be omitted from training because it originates from an outdated version of the process. Knowledge about this also impacts whether or how often models need to be retrained and on which data.\\

\noindent\textbf{Data augmentation:} In machine learning applications for computer vision, training images are rotated or transformed to produce additional training data. In the interest of improving model performance, such methods could also be explored for process traces.\\

\noindent\textbf{Word Embeddings:} In \autoref{sec:background:feature-engineering} we hinted at the fact that the weights for word embeddings in NLP applications can imported from pre-trained models. This could be transferred to Predictive Process Monitoring by providing Embeddings for process categories. As evidenced in \autoref{sec:eval:discussion}, this is tied to larger datasets and would require high standardization of the process names, which in turn most likely makes the process very predictable.

\section{Verdict} \label{sec:conclusion:verdict}
In this thesis, we compared four different neural network architectures predicting the next activity in a running case for accuracy, training time and stability of the results. The comparison was implemented in Python and Keras and yielded a neural network training framework for Predictive Process Monitoring. The framework enables comparison of different batching strategies for variable-length traces across all models and datasets, which makes it possible to understand the merits of each batching strategy.

The framework not only allows for a trivial execution of numerous model-strategy-dataset combinations, but also tackles an issue within current research: comparability. Most publications in Predictive Process Monitoring use different datasets and do not publicize their implementation, thus making comparisons hard. This framework could help researchers get results faster and on more datasets until benchmarking datasets are established.\\

Two of the four neural network models were reimplemented from publications by Evermann et al. and Schoenig et al. to establish a baseline~\cite{evermann2016, schoenig2018}. We then ported an approach from NLP to result in a third model~\cite{shibata2016bipartite} and adapted its input features according to the findings of another publication~\cite{klinkmuller2018reliablemonitoring} for the fourth model. The models are referred to as EVM, SCH, SP2 and PFS.

The SP2 model consistently ranked at the top or among the best performing models, which we attribute to the engineered features. In a comparison with recently published accuracy numbers on the BPIC12 dataset, the SP2 model also outperformed~\cite{boehmer2018probability, evermann2016}. Furthermore, we established that grouping sequences by length to produce batches yields the highest accuracies. Generally, the batching approaches which supply complete history to the model perform best, with the strategy of a single trace per batch seeing the smallest gains. Hereby, we could confirm findings from another paper that omitting history from traces negatively impacts accuracy~\cite{klinkmuller2018reliablemonitoring}.\\

We hope that by focusing on the technicalites of input data, this research improves the groundwork for better comparability in Predictive Process Monitoring publications and an improved understading of the impact that batching strategies can have on model accuracy.
