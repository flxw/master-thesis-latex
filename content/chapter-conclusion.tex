\chapter{Conclusion} \label{chap:conclusion}
This chapter concludes this thesis. In \autoref{sec:conclusion:future-work}, we want to take the opportunity to elaborate on steps with which to carry this research further in publications or subsequent master thesises. In \autoref{sec:conclusion:verdict} we briefly recapitulate on this thesis and draw it to a conclusion.

\section{Future Work} \label{sec:conclusion:future-work}
We cluster the future work items and highlight why we believe the respective item to be of importance:\\

\noindent\textbf{Benchmarking dataset:} Everything in machine learning starts and ends with the available data. Based on the numerous publications on Predictive Process Monitoring we read, we believe that it is time to draw up exemplary benchmarking datasets close to real-world scenarios. Maybe these datasets can represent industry-typical processes. Otherwise the number of datasets to use to ensure comparability will only ever increase.\\

\noindent\textbf{Imbalanced classes:} While our approach at preprocessing the data covered the basics, a necessity to balance the distribution of classes in the target data remains. While we do not believe it is viable to modify the traces themselves, weighting classes based on their occurence in the current batch might be an option which could see accuracy gains as models learn better with a balanced target class distribution~\cite{web:stackoverflow-keras-class-weights}.\\

\noindent\textbf{PFS feature engineering and hyper-parameter tuning:} The PFS model features  were chosen to be the 25 closed sub-sequences with the highest support. This threshold should be questioned and explored further. Furthermore, none of the model's hyper-parameters were optimized for lack of a functional framework. In this area, another contribution can be made.\\

\noindent\textbf{Concept drift:} Processes change over time and so does the content of their event logs. It is worth investigating at which point data in an event log can be omitted from training because it originates from an outdated process. Knowledge about this also impacts how often models need to be retrained and with which data.\\

\noindent\textbf{Data augmentation:} In computer vision machine learning applications, training images is rotated or transformed to produce additional training data. In the interest of improving model performance, such methods could also be explored for process traces.

\section{Verdict} \label{sec:conclusion:verdict}
