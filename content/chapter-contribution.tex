\chapter{Contribution}\label{chap:contribution}
While a sufficient number of works have demonstrated the applicability of LSTM neural networks in Predictive Process Monitoring, most have left out general perspectives on the sequence prediction problem from NLP.
In this chapter we outline our contributions, with which we aim to help improve the points mentioned in \autoref{sec:intro:contribution}. In doing so, we provide a high-level overview over the contributions which will be implemented and evaluated in the next chapter.

We connect process prediction to sequence prediction by harmonizing its definition in \autoref{sec:contrib:case-sequence-understanding}. This delivers the underpinning for introducing a NLP-inspired perspective on the problem. We achieve this through adapting the approach of Shibata et al.~\cite{shibata2016bipartite} for Predictive Process Monitoring in \autoref{sec:contrib:nlp-inspiration}. During development, we realized that there are highly divergent understandings regarding the data input of neural networks for next-element predictions with sequences. The different data input formats which are evaluated in the next chapter are described in \autoref{sec:contrib:input-formatting}. Finally, we aim at both technical understanding and reproducibility issues by providing a simple training framework in \autoref{sec:contrib:training-framework} that could be easily expanded by future researchers.

\section{Understanding a trace as a sequence}
\label{sec:contrib:case-sequence-understanding} 
The definition for sequences presented in \autoref{sec:background:sequence-prediction} needs to be extended so that a case trace can be understood as a sequence.

In the previous definition, the set $I$ had been used for \textit{items}, out of which itemsets are comprised. In this extension, an itemset represents a single row in a log. As such a row is made up of multiple different elements and adheres to a fixed schema, the definition needs to account for these two properties.\\

First, the set $I$ is now understood as a union of the sets $C_i$ which make up the distinct values inside one of the $n$ columns of a trace:
$$I = \bigcup\limits_{i=1}^{n} C_{i}$$

Second, each itemset $s$ needs to be bound by a specific schema. The schema needs to match the schema of the log and can be defined as such: $s = <i_1, i_2 ..., i_i>$ with $i_i \in C_i$. Thus, the original condition $s \subseteq I$ still holds true, but every item now has a fixed place in the itemset depending on which column it originates from.

\section{Taking inspiration from approaches in NLP}
\label{sec:contrib:nlp-inspiration}
Shibata et al.'s bipartite network architecture in combination with engineered SP-2 features has shown extraordinary performance in the SPiCE competition \cite{web:spice}. Under the hypothesis that a case can exhibit properties similar to grammatical rules, we adapt it for use in the business process domain. Furthermore, we consider sub-sequence information as proposed by Klinkmüller et al.~\cite{klinkmuller2018reliablemonitoring} as an alternative to the SP-2 features.

The two variations are henceforth referred to as SP2 for the bipartite architecture using SP-2 features and PFS for the bipartite architecture using sub-sequence information. 
%They are compared to the performance of implementations that mimic Evermann et al. and Schönig et al. Where original performance statistics were published, these are used additionally. The BPIC2011 \cite{BPIC2011} and BPIC2017 \cite{BPIC2017} datasets are used and preprocessed differently as per each approach.\\

In \autoref{fig:sp2-pfs-architecture}, the SP2 and PFS architecture is displayed. While the general architecture has been adapted by Shibata et al., important details were taken from Schönig et al.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{gfx/sp2-network-architecture.png}
    \caption{The SP2 and PFS networks share the architecture but inject different features.}
    \label{fig:sp2-pfs-architecture}
\end{figure}

Both SP2 and PFS models use $n$ units on the first input layer denoting the number of features for the encoded activities, timestamps and other event attributes. Both put out the next activity in one-hot encoded form through $m$ units, thus modelling the task as a multi-classification problem.

In contrast to Evermann et al. and Shibata et al., the number of units $m+n$ in the LSTM layers is a function of the input unit count and the output unit count. This follows general advice not to introduce bottlenecks in the hidden layers by using fewer units than required in the output layer. Furthermore, dropout layers have been introduced to prevent overfitting.

The SP2 and PFS features are fed in higher up on the right side of the tree, passing through a ReLU-activated, fully-connected layer, before the intermediate values are concatenated. Finally, the concatenated vectors are processed by fully-connected layers, with the commonly used Softmax activation function producing the final classification.

\section{Contrasts among sequence input formats}
\label{sec:contrib:input-formatting}
We implemented the SP2 and PFS variants as well as the comparison models using Python and the Keras neural networks API. While doing so, a wide range of recommended approaches to training the models were noted in relevant publications and on online platforms such as StackOverflow.\\

While some recommend sliding window approaches, others deem this against the concept of LSTM cells. Especially, Klinkmüller et al. argue against it: "[...]the popular strategy of cutting traces to certain prefix lengths to learn prediction models for ongoing instances is prone to yield unreliable models"~\cite{klinkmuller2018reliablemonitoring}. Again others argue that padding sequences to equal length makes training faster and does not affect accuracy. Furthermore, the batch size represents an important hyper-parameter, and no guidelines how to sort traces into batches were found. We believe that the understanding of the merits of each approach is of general value to any application of sequence prediction and make it part of our contribution.\\

When using Keras' implementation of LSTM, it is stateful \textit{during} a batch, and resets the internal state before the next one, unless specified otherwise. For the sake of simplicity, it is advisable to keep related data inside a single batch. Translated to traces, this means keeping a trace completely inside a batch. The Keras LSTM layers expect data to arrive in a three-dimensional array of fixed size for every batch, where each dimension has a defined meaning:

$$(n_{samples}, n_{timesteps}, n_{features})$$

Each sample contains a number of timesteps $n_{timesteps}$ containing a number of features $n_{features}$, which is a constant. For each sample, the LSTM layer maintains a separate state, meaning that several traces can be trained on simultaneously~\cite{web:keras-lstm-state}. As the batches themselves need not to have the same dimensions, this definition opens up a range of possibilities, four of which we are comparing in the next chapter. To the best of our knowledge, these have not been compared in this context yet.\\

First and most straightforward, one trace can be trained per batch. This fulfills the requirement of constant dimensions, since only a single sample is used.

Secondly, \textit{some} traces can be trained inside a single batch. This is possible if all traces inside one batch have the same number of timesteps, i.e. have the same length. The number of samples and timesteps may vary between batches. A look at a trace length distribution in \autoref{fig:bpic2011-length-distribution} reveals that grouped batching might bias the model toward longer traces that are smaller in number as they are trained in batches of their own.

Third, there is the possibility of padding the number of time-steps in a sequence to the same length and using a Masking\footnote{\url{https://keras.io/layers/core/\#masking} (last visited on December 12, 2018)} layer to then filter out the padded values during training. This is likely to incur a performance hit due to the higher memory requirements for padded samples and processing overhead for filtering out the padding values during training.

Fourth and finally, there is also the possibility to split the trace into samples by sliding a window along it. This results in $l-w+1$ samples for a trace of length $l$ and a window width $w$. Taking \autoref{tab:sliding-window} in \autoref{sec:background:feature-engineering} as an example, the window would be two timesteps wide. While this approach solves the problem of unequal sample lengths and facilitates batch construction, the model can only use a maximum of $w$ timesteps per sample for training, thus losing potential long-term dependencies. As both Evermann et al.~\cite{evermann2016} and Schönig et al.~\cite{schoenig2018} use this format and it directly opposes the findings of Klinkmüller et al.~\cite{klinkmuller2018reliablemonitoring}, we investigate it. Furthermore, we believe that a windowed training data format misses out on LSTM potential.\\

The four different input formats are labelled in the order of the preceding description for easier reference in the next chapter:
\begin{itemize}
    \item\textbf{Individual}: One trace per batch
    \item\textbf{Grouped}: Same-length traces in one batch
    \item\textbf{Padded}: Padded-to-length traces
    \item\textbf{Windowed}: Windowed samples, as used by Evermann and Schönig
\end{itemize}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=.9\textwidth]{gfx/frequency-distribution.png}
    \caption{Distribution of trace lengths in the BPIC2011 training set.}
    \label{fig:bpic2011-length-distribution}
\end{figure}

\section{A next-event predictive model training framework}
\label{sec:contrib:training-framework}
We realize that making different process prediction approaches comparable is not only a technical but also a data challenge - no established benchmarking datasets for Predictive Process Monitoring exist yet.
To mitigate this situation, we designed the software framework that helped us compare the sixteen total model-formatting combinations on three different datasets in an extensible way. Doing so enables future researchers to build upon this framework and publish performance numbers from models that were trained on the same data.\\

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{gfx/training-framework-classes.png}
    \caption{A Unified Modeling Language (UML) diagram of the abstract base class inheritance structure of Builders and Formatters.}
    \label{fig:trainig-framework-classes}
\end{figure}

The framework distinguishes between two important concepts:
Builders and Formatters.
To allow for easy building with these concepts, \autoref{fig:trainig-framework-classes} shows that abstract base classes were introduced.

Builders construct Keras models and also define the structure of the training and test sets. This is important as models may not only have one input layer, but two or more. These pre-formatted data sets are not structured into batches yet. One such Builder is implemented for every model type by inheriting from the abstract base class \verb=AbstractBuilder=.

Formatters take the pre-formatted data sets and structure them into batches. For each batch format, one class inherits from the abstract base class \verb=AbstractFormatter=.\\

A frontend named \verb=model_runner= ties these concepts together, and provides a basic command-line interface for directing model training to a specific GPU, the saving directory for the output files and the location of the input files. It is shown in \autoref{fig:framework-frontend}.
\begin{figure}
\centering
\begin{verbatim}
usage: model_runner.py [-h] [--gpu GPU]
                       [--output OUTPUT]
                       {evermann,schoenig,sp2,pfs}
                       {padded,grouped,individual,windowed}
                       datapath

The network training framework script for Felix Wolff's master's thesis!

positional arguments:
  {evermann,schoenig,sp2,pfs}
                        Which type of model to train.
  {padded,grouped,individual,windowed}
                        Which mode to use for feeding
                        the data into the model.
  datapath              Path of dataset to use for training.

optional arguments:
  -h, --help            show this help message and exit
  --gpu GPU             CUDA ID of which GPU the model
                        should be placed on to
  --output OUTPUT       Target directory to put model
                        and training statistics
\end{verbatim}
\caption{The \texttt{model\_runner} command-line frontend for the training framework. TODO improve the wording here}
\label{fig:framework-frontend}
\end{figure}