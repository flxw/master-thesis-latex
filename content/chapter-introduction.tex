\chapter{Introduction}\label{sec:intro}
\begin{flushright}{\slshape
I choose a lazy person to do a hard job,\\
because a lazy person will find an easy way to do it.}\\
\medskip
--- Bill Gates
\end{flushright}

\noindent Since the dawn of time, humanity has always tried to find ways to make work easier. With the start of the industrial revolution, this was achieved by constructing machines and other helpful contraptions which automated a task. In more recent years, a guiding procedure - a process - was installed to streamline the workflow where complete automation was not possible. With the rise of the credo "what gets measured, gets managed", key performance indicators (KPIs) were installed into manual labor processes to optimize process efficiency further~\cite{web:taylorism-and-drucker}.\\

However, processes and KPIs fell short of penetrating and improving the realm of knowledge work, since the foundational mechanics of it differ strongly from manual labor. Peter F. Drucker, a renowned management educator, realized this in 1999:
"The most important contribution of management in the 20th century was to increase manual worker productivity fifty-fold. The most important contribution of management in the 21st century will be to increase knowledge worker productivity — hopefully by the same percentage"~\cite{drucker1999}.\\

In the spirit of Drucker's statement and by leveraging the technical developments of the years since his statement, we apply deep learning on business process execution history to predict the next activity in a running business process. We focus on deep learning methods because they have been shown to outperform others in this use case~\cite{tax2018interdisciplinary}. How this is a step toward process automation in knowledge work, will be explained further in \autoref{sec:intro:motivation}.  We highlight the resulting contribution to current research in \autoref{sec:intro:contribution}. The chapter ends in \autoref{sec:intro:outline} with a description of the thesis outline.

\section{Motivation} \label{sec:intro:motivation}
Automation of work is a phenomenon that has occurred in the past with manual labor and is spreading into other types of work today, namely knowledge work. As mentioned before, manual labor and knowledge work differ:

The course of manual labor is determined by physical laws, is often very structured, and thus offers great potential for simple automation - like work at an assembly line. Knowledge work, on the other hand, requires workers to "think for a living" and is strongly shaped by the individuality of the thoughts and habits of each knowledge worker~\cite{drucker1999}. As each worker has a different knowledge background and uses information differently, this type of work is very flexible, and often no process is executed exactly the same~\cite{hewelt2016}. Popular examples of knowledge work are insurance claims, handled by several employees. Each claim requires a different course of action since the information contained in each case differs.\\

The following 20 years since Drucker's mission statement saw the analog tools of knowledge workers evolve into a plethora of digital systems and applications. These help make their decisions more informed and faster. Furthermore, these systems also track work progress, resulting in a large number of logs which document the course that work on a running process has taken. Running processes are also referred to as cases.\\

These logs are a valuable source of information as they can reveal best practices that knowledge workers use in certain situations. An assistance system could work with this data and recommend such best practices in specific circumstances. These knowledge worker assistance systems have been called for in recent literature reviews by Hauder et al.~\cite{hauder2014} and Francescomarino et al.~\cite{francescomarino2018}, but have only been implemented prototypically until now. One of the challenges that lie in the way of creating assistance systems is the task of anticipating the development of a case and foreseeing which part comes next. Once then a machine understands the \textit{what} and is only missing the \textit{how}, the ability to forecast process developments can be interpreted as a step toward process automation.\\

Forecasting the course of a running process can be useful for workers doing either manual labor or knowledge work. Questions of time and outcome dominate manual labor because the course of work is clear - natural interests in a world of distributed supply chains and just-in-time production~\cite{web:economist:jit}. The course of the work itself is of importance in the case of unstructured knowledge work, which is often unclear and depends on the information handled inside a case~\cite{francescomarino2015}. If a case were to progress in an unwanted fashion, knowledge about this development would present workers with an opportunity to intervene.\\

By regarding the execution history of an ongoing case, the prediction of its next activity is possible - illustrated in \autoref{fig:next-activity-prediction}. This prediction could then be processed further by the aforementioned assistance system. It proposes an intervention if a case takes an unwanted course, for example. The application of Predictive Analytics on business processes enables this type of prediction. It is relatively new and is commonly referred to as Predictive Process Monitoring.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{gfx/next-activity-prediction.pdf}
    \caption[Next-activity prediction from a trace]{The next activity of a case is predicted from the sequence of elapsed activities in its trace}
    \label{fig:next-activity-prediction}
\end{figure}

We realized that the current research in this young domain could be improved in three areas. These will henceforth be referred to as improvement areas:

\begin{enumerate}
  \item[\textbf{Area 1}] NLP-Influence: The history of a case is essentially a sequence, but little inspiration was taken from Natural Language Processing (NLP), where sequence prediction is common~\cite{shibata2016bipartite, kokkinos2017structural}.
  \item[\textbf{Area 2}] Reproducibility: Divergent approaches to training the prediction models and low technical depth of the publications make it hard to reproduce the published results. Furthermore, some prediction approaches focus on whole event streams without specific regard to a case~\cite{evermann2016, schoenig2018}.
  \item[\textbf{Area 3}] Comparability: Published approaches often use different datasets, making them hard to compare.
\end{enumerate}

\section{Contribution}\label{sec:intro:contribution}
In this work, we make a contribution to ongoing research by applying neural networks to process execution logs to predict the next activity. The three improvement areas guided the work.

We address Area 1 by reusing a successful sequence prediction approach from the NLP domain and applying it on business process log data. We also adapt it to incorporate learnings from a paper on feature engineering for Predictive Process Monitoring~\cite{klinkmuller2018reliablemonitoring}. We compare the two models to reimplementations of two published approaches. Doing so, we ensure the direct comparability mentioned in Improvement Area 3. The models were reverse-engineered from the following publications:

\begin{enumerate}
    \item\textit{A Deep Learning Approach for Predicting Process Behaviour at Runtime} by Evermann et al.~\cite{evermann2016}
    \item\textit{Deep Learning Process Prediction with Discrete and Continuous Data Features} by Schönig et al.~\cite{schoenig2018}.
\end{enumerate}

During reverse engineering, we uncovered widely divergent understandings of batch construction for neural networks from sequential data. To contribute to a better understanding in this area, we include a comparison of four different batching strategies into the evaluation.

As we remarked the comparability of current publications in Improvement Area 3, we include a training framework in this thesis. It allowed us to train four different models with four different batching strategies on eight prepared datasets with ease. It is extensible for other researchers to facilitate comparisons in future works.

We use the datasets from the Business Process Intelligence Competition (BPIC) years 2011, 2012, and 2015, where the latter consists of five datasets.
The trace characteristics in each dataset differ.
From these traits and the different accuracies, we infer a suggestion on which batching strategy could be preferrable to use on which flavor of process log.
The additional use of the HelpDesk log allows for a comparison to published next-activity prediction approaches.

We evaluate the trained models using three criteria: First, total accuracy. Second, we test for accuracy stability across the whole execution of the process, which we believe is vital for putting trust into the model~\cite{francescomarino2015, boehmer2018probability}. Third, we investigate training time requirements.

From the three evaluation criteria, we reason about the effectiveness of certain model-batching-strategy combinations.

\section{Thesis outline}\label{sec:intro:outline}
\autoref{chap:background} delivers the necessary background on Process Science and Predictive Analytics. Furthermore, it provides information on Predictive Model Development as well as details on the inner workings of the used type of neural network.

\autoref{chap:related-work} gives an overview of current approaches to the prediction task at hand, highlighting the achievements and technicalities of each publication. Furthermore, it presents works on the problem of sequence prediction in the field of Natural Language Processing (NLP). For each publication used as comparison, implementation details are discussed.

In \autoref{chap:taking-inspiration}, we show how sequences relate to business processes.
We then go on to adopt a winning approach from an NLP sequence prediction competition for Predictive Process Monitoring.

In \autoref{chap:training-framework}, we describe the various possible batch construction strategies that we perceived during the implementation of the predictive models and the exchange with Jörg Evermann and Stephan Schönig. We expand this technical issue into a simple training framework that makes it possible to compare all models and batching strategies side-by-side on all datasets. The framework permits future researchers to train sequence prediction models faster and more consistent.

We bring both of the contributions mentioned above together in \autoref{chap:methodology}.
This chapter presents the methodology we followed to obtain our results.
It includes a description of the process logs, why we chose them, and how we prepared them for model training.
Furthermore, we include a description of our technology landscape.

In \autoref{chap:evaluation} we present the results obtained from our experiments, and the insights gained. As described in the previous section, we not only focus on total model accuracy, but also the stability of the predictions as a case progresses and more history becomes available.

The thesis ends in \autoref{chap:conclusion}, where we summarize the findings and the accomplishments of this thesis. Also, we give pointers with which to extend this work and carry Predictive Process Monitoring forward.
